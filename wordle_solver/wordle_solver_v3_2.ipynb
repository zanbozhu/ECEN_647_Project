{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "allied-siemens",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import pickle\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import entropy\n",
    "import altair as alt\n",
    "from wordfreq import word_frequency\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "selective-exhibition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_guess_result(answer_word, guess_word):\n",
    "\n",
    "    guess_result = [0, 0, 0, 0, 0]\n",
    "    for i in range(5):\n",
    "        if guess_word[i] == answer_word[i]:\n",
    "            guess_result[i] = 2\n",
    "    \n",
    "    letter_count = {}\n",
    "    for i in range(5):\n",
    "        if guess_result[i] != 2:\n",
    "            if answer_word[i] not in letter_count:\n",
    "                letter_count[answer_word[i]] = 1\n",
    "            else:\n",
    "                letter_count[answer_word[i]] += 1\n",
    "    \n",
    "    for i in range(5):\n",
    "        if guess_result[i] != 2 and guess_word[i] in letter_count:\n",
    "            if letter_count[guess_word[i]] > 0:\n",
    "                guess_result[i] = 1\n",
    "                letter_count[guess_word[i]] -= 1\n",
    "\n",
    "    return int(''.join(str(n) for n in guess_result), 3)\n",
    "\n",
    "######################################################################################################################################################\n",
    "\n",
    "def display_result(answer_word, former_guesses, former_guess_results, num_choices_left, total_guess_number, result_distribution):\n",
    "\n",
    "    former_guesses = former_guesses[-6:]\n",
    "    former_guess_results = former_guess_results[-6:]\n",
    "    num_choices_left = num_choices_left[-6:]\n",
    "\n",
    "    ternary_string_guess_results = []\n",
    "    for number in former_guess_results:\n",
    "        ternary_string_guess_results.append(np.base_repr(number, base = 3).zfill(5))\n",
    "\n",
    "    if former_guess_results[-1] != 242:\n",
    "        if total_guess_number == 0:\n",
    "            average_guess = 0\n",
    "        else:\n",
    "            average_guess = total_guess_number / possible_words_list.index(answer_word)\n",
    "    else:\n",
    "        average_guess = total_guess_number / (possible_words_list.index(answer_word) + 1)\n",
    "\n",
    "    message_1 = ''.join(['| ', '{:4.0f}'.format(possible_words_list.index(answer_word) + 1), ' of ', str(len(possible_words_list)), ' | word: ', answer_word, ' |'])\n",
    "    message_2 = ''.join(['| total guess: ', '{:5.0f}'.format(total_guess_number), ' | average guess: ', '{:5.4f}'.format(average_guess), ' | guess number distribution: ', str(result_distribution), ' |'])\n",
    "\n",
    "    print(message_1)\n",
    "    print('-------------------------')\n",
    "\n",
    "    for result_display_line in range(6):\n",
    "        if result_display_line < len(ternary_string_guess_results):\n",
    "            result_string = ternary_string_guess_results[result_display_line]\n",
    "            new_result_string = ''\n",
    "            for string_bit in range(5):\n",
    "                if result_string[string_bit] == '0':\n",
    "                    new_result_string += '\\U00002B1B'\n",
    "                elif result_string[string_bit] == '1':\n",
    "                    new_result_string += '\\U0001F7E8'\n",
    "                elif result_string[string_bit] == '2':\n",
    "                    new_result_string += '\\U0001F7E9'\n",
    "            new_result_string += '  '\n",
    "            new_result_string += former_guesses[result_display_line]\n",
    "            new_result_string += '  '\n",
    "            new_result_string += str(num_choices_left[result_display_line])\n",
    "            print(new_result_string)\n",
    "        else:\n",
    "            print()\n",
    "\n",
    "    print('-------------------------')\n",
    "    print(message_2)\n",
    "\n",
    "######################################################################################################################################################\n",
    "\n",
    "def get_next_guess(former_guesses, former_guess_results):\n",
    "\n",
    "    possible_choices = np.arange(len(possible_words_list))\n",
    "    for i in range(len(former_guesses)):\n",
    "        possible_choices = np.intersect1d(possible_choices, np.where(guess_result_matrix[allowed_words_list.index(former_guesses[i])] == former_guess_results[i]))\n",
    "    \n",
    "    if len(former_guesses) == 1:\n",
    "        return best_second_guess_dict[former_guess_results[0]], len(possible_choices)\n",
    "    \n",
    "    else:\n",
    "        if len(possible_choices) == 1:\n",
    "            return possible_words_list[possible_choices[0]], len(possible_choices)\n",
    "        else:\n",
    "            sub_matrix = guess_result_matrix[np.ix_(np.arange(len(guess_result_matrix)), possible_choices)]\n",
    "            entropy_value_array = []\n",
    "            for i in range(len(sub_matrix)):\n",
    "                unique, counts = np.unique(sub_matrix[i], return_counts = True)\n",
    "                entropy_value_array.append(entropy(counts, base = 2))\n",
    "\n",
    "            argmax = np.where(entropy_value_array == np.max(entropy_value_array))\n",
    "            if np.in1d(np.array(possible_words_indices)[possible_choices], argmax).any():\n",
    "                best_next_guess = allowed_words_list[np.array(possible_words_indices)[possible_choices][np.in1d(np.array(possible_words_indices)[possible_choices], argmax)][0]]\n",
    "            else:\n",
    "                best_next_guess = allowed_words_list[np.argmax(entropy_value_array)]\n",
    "                \n",
    "            return best_next_guess, len(possible_choices)\n",
    "\n",
    "######################################################################################################################################################\n",
    "\n",
    "def demo():\n",
    "    \n",
    "    np.set_printoptions(suppress = True)\n",
    "    \n",
    "    result_distribution = np.zeros(7)\n",
    "    total_guess_number = 0\n",
    "\n",
    "    for answer_word in possible_words_list:\n",
    "\n",
    "        first_guess = 'slane'\n",
    "        guess_number = 0\n",
    "        former_guesses = []\n",
    "        former_guess_results = []\n",
    "        num_choices_left = []\n",
    "\n",
    "        guess_word = first_guess\n",
    "        while answer_word != guess_word:\n",
    "            guess_number += 1\n",
    "            guess_result = get_guess_result(answer_word, guess_word)\n",
    "            former_guesses.append(guess_word)\n",
    "            former_guess_results.append(guess_result)\n",
    "            next_guess, len_possible_choices = get_next_guess(former_guesses, former_guess_results)\n",
    "            num_choices_left.append(len_possible_choices)\n",
    "            guess_word = next_guess\n",
    "\n",
    "            clear_output(wait = True)\n",
    "            display_result(answer_word, former_guesses, former_guess_results, num_choices_left, total_guess_number, result_distribution)\n",
    "\n",
    "        former_guesses.append(answer_word)\n",
    "        former_guess_results.append(242)\n",
    "        num_choices_left.append('')\n",
    "        guess_number += 1\n",
    "        total_guess_number += guess_number\n",
    "        if guess_number <= 6:\n",
    "            result_distribution[guess_number - 1] += 1\n",
    "        else:\n",
    "            result_distribution[6] += 1\n",
    "\n",
    "        clear_output(wait = True)\n",
    "        display_result(answer_word, former_guesses, former_guess_results, num_choices_left, total_guess_number, result_distribution)\n",
    "\n",
    "    display(alt.Chart(pd.DataFrame({'number of guesses': [str(num) for num in np.arange(len(result_distribution) - 1) + 1] + ['> 6'], 'count': result_distribution})).mark_bar().encode(alt.X('number of guesses:O'), alt.Y('count:Q'), tooltip = ['number of guesses', 'count']).properties(width = 500, height = 200).configure_axisX(labelAngle = 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "thick-chamber",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('possible_words.txt') as file:\n",
    "    possible_words = file.readlines()\n",
    "possible_words_list = [word[:5] for word in possible_words]\n",
    "\n",
    "with open('allowed_words.txt') as file:\n",
    "    allowed_words = file.readlines()\n",
    "allowed_words_list = [word[:5] for word in allowed_words]\n",
    "\n",
    "######################################################################################################################################################\n",
    "\n",
    "if 'guess_result_matrix.npy' not in os.listdir():\n",
    "    guess_result_matrix = []\n",
    "    for word1 in allowed_words_list:\n",
    "        word_guess_result_array = []\n",
    "        for word2 in allowed_words_list:\n",
    "            word_guess_result_array.append(get_guess_result(word2, word1))\n",
    "        guess_result_matrix.append(word_guess_result_array)\n",
    "    np.save('guess_result_matrix.npy', guess_result_matrix)\n",
    "else:\n",
    "    guess_result_matrix = np.load('guess_result_matrix.npy')\n",
    "\n",
    "possible_words_indices = []\n",
    "for i in range(len(possible_words_list)):\n",
    "    possible_words_indices.append(allowed_words_list.index(possible_words_list[i]))\n",
    "guess_result_matrix = guess_result_matrix[np.ix_(np.arange(len(guess_result_matrix)), possible_words_indices)]\n",
    "\n",
    "######################################################################################################################################################\n",
    "\n",
    "if 'best_second_guess_dict_v3_2_slane.pkl' not in os.listdir():\n",
    "\n",
    "    unique, counts = np.unique(guess_result_matrix[allowed_words_list.index('slane')], return_counts = True)\n",
    "\n",
    "    best_second_guess_array = []\n",
    "    for possible_result in unique:\n",
    "\n",
    "        possible_choices = np.where(guess_result_matrix[allowed_words_list.index('slane')] == possible_result)[0]\n",
    "\n",
    "        if len(possible_choices) == 1:\n",
    "            best_second_guess = possible_words_list[possible_choices[0]]\n",
    "        else:\n",
    "            sub_matrix = guess_result_matrix[np.ix_(np.arange(len(guess_result_matrix)), possible_choices)]\n",
    "            entropy_value_array = []\n",
    "            for i in range(len(sub_matrix)):\n",
    "                unique_2, counts_2 = np.unique(sub_matrix[i], return_counts = True)\n",
    "                entropy_value_array.append(entropy(counts_2, base = 2))\n",
    "\n",
    "            argmax = np.where(entropy_value_array == np.max(entropy_value_array))\n",
    "            if np.in1d(np.array(possible_words_indices)[possible_choices], argmax).any():\n",
    "                best_second_guess = allowed_words_list[np.array(possible_words_indices)[possible_choices][np.in1d(np.array(possible_words_indices)[possible_choices], argmax)][0]]\n",
    "            else:\n",
    "                best_second_guess = allowed_words_list[np.argmax(entropy_value_array)]\n",
    "\n",
    "        best_second_guess_array.append(best_second_guess)\n",
    "\n",
    "    best_second_guess_dict = dict(zip(unique, best_second_guess_array))\n",
    "    pickle.dump(best_second_guess_dict, open('best_second_guess_dict_v3_2_slane.pkl', 'wb'))\n",
    "\n",
    "else:\n",
    "    best_second_guess_dict = pickle.load(open('best_second_guess_dict_v3_2_slane.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "green-findings",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_guess_entropy_array = []\n",
    "for i in range(len(guess_result_matrix)):\n",
    "    unique, counts = np.unique(guess_result_matrix[i], return_counts = True)\n",
    "    first_guess_entropy_array.append(entropy(counts, base = 2))\n",
    "\n",
    "if 'two_step_entropy_df_20_v3_2.pkl' not in os.listdir():\n",
    "\n",
    "    two_step_entropy_df = pd.DataFrame(index = allowed_words_list, columns = ['first_step_entropy', 'second_step_entropy', 'sum'])\n",
    "    two_step_entropy_df['first_step_entropy'] = first_guess_entropy_array\n",
    "    two_step_entropy_df_20 = two_step_entropy_df.sort_values(by = 'first_step_entropy', ascending = False)[:20]\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "    for first_word in two_step_entropy_df_20.index:\n",
    "\n",
    "        unique, counts = np.unique(guess_result_matrix[allowed_words_list.index(first_word)], return_counts = True)\n",
    "\n",
    "        expected_second_step_entropy = 0\n",
    "        for i in range(len(unique)):\n",
    "            guess_result = unique[i]\n",
    "            guess_result_weight = counts[i] / np.sum(counts)\n",
    "\n",
    "            if counts[i] == 1:\n",
    "                max_second_entropy = 0\n",
    "            elif counts[i] == 2:\n",
    "                max_second_entropy = 1\n",
    "            else:\n",
    "                possible_choices = np.where(guess_result_matrix[allowed_words_list.index(first_word)] == guess_result)[0]\n",
    "                sub_matrix = guess_result_matrix[np.ix_(np.arange(len(guess_result_matrix)), possible_choices)]\n",
    "\n",
    "                second_entropy_value_array = []\n",
    "                for j in range(len(sub_matrix)):\n",
    "                    unique_2, counts_2 = np.unique(sub_matrix[j], return_counts = True)\n",
    "                    second_entropy_value_array.append(entropy(counts_2, base = 2))\n",
    "                max_second_entropy = np.max(second_entropy_value_array)\n",
    "\n",
    "            expected_second_step_entropy += guess_result_weight * max_second_entropy\n",
    "\n",
    "\n",
    "        two_step_entropy_df_20.at[first_word, 'second_step_entropy'] = expected_second_step_entropy\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "    two_step_entropy_df_20['sum'] = two_step_entropy_df_20['first_step_entropy'] + two_step_entropy_df_20['second_step_entropy']\n",
    "    pickle.dump(two_step_entropy_df_20, open('two_step_entropy_df_20_v3_2.pkl', 'wb'))\n",
    "\n",
    "else:\n",
    "    two_step_entropy_df_20 = pickle.load(open('two_step_entropy_df_20_v3_2.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "recorded-region",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_step_entropy</th>\n",
       "      <th>second_step_entropy</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>slane</th>\n",
       "      <td>5.768957</td>\n",
       "      <td>4.26746</td>\n",
       "      <td>10.0364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slate</th>\n",
       "      <td>5.855819</td>\n",
       "      <td>4.17595</td>\n",
       "      <td>10.0318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salet</th>\n",
       "      <td>5.836023</td>\n",
       "      <td>4.18091</td>\n",
       "      <td>10.0169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace</th>\n",
       "      <td>5.830429</td>\n",
       "      <td>4.1827</td>\n",
       "      <td>10.0131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crate</th>\n",
       "      <td>5.835216</td>\n",
       "      <td>4.17736</td>\n",
       "      <td>10.0126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reast</th>\n",
       "      <td>5.867738</td>\n",
       "      <td>4.14346</td>\n",
       "      <td>10.0112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carle</th>\n",
       "      <td>5.769364</td>\n",
       "      <td>4.23667</td>\n",
       "      <td>10.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carte</th>\n",
       "      <td>5.795107</td>\n",
       "      <td>4.20188</td>\n",
       "      <td>9.99699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soare</th>\n",
       "      <td>5.885203</td>\n",
       "      <td>4.1063</td>\n",
       "      <td>9.99151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raile</th>\n",
       "      <td>5.865154</td>\n",
       "      <td>4.12528</td>\n",
       "      <td>9.99044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roate</th>\n",
       "      <td>5.884856</td>\n",
       "      <td>4.09964</td>\n",
       "      <td>9.9845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stare</th>\n",
       "      <td>5.806889</td>\n",
       "      <td>4.17742</td>\n",
       "      <td>9.98431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caret</th>\n",
       "      <td>5.778207</td>\n",
       "      <td>4.19784</td>\n",
       "      <td>9.97604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raine</th>\n",
       "      <td>5.786193</td>\n",
       "      <td>4.18608</td>\n",
       "      <td>9.97227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irate</th>\n",
       "      <td>5.832799</td>\n",
       "      <td>4.13097</td>\n",
       "      <td>9.96377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raise</th>\n",
       "      <td>5.878303</td>\n",
       "      <td>4.07497</td>\n",
       "      <td>9.95327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orate</th>\n",
       "      <td>5.818944</td>\n",
       "      <td>4.13192</td>\n",
       "      <td>9.95086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ariel</th>\n",
       "      <td>5.774557</td>\n",
       "      <td>4.16077</td>\n",
       "      <td>9.93532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arise</th>\n",
       "      <td>5.821023</td>\n",
       "      <td>4.11102</td>\n",
       "      <td>9.93204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taler</th>\n",
       "      <td>5.773100</td>\n",
       "      <td>4.15885</td>\n",
       "      <td>9.93195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       first_step_entropy second_step_entropy      sum\n",
       "slane            5.768957             4.26746  10.0364\n",
       "slate            5.855819             4.17595  10.0318\n",
       "salet            5.836023             4.18091  10.0169\n",
       "trace            5.830429              4.1827  10.0131\n",
       "crate            5.835216             4.17736  10.0126\n",
       "reast            5.867738             4.14346  10.0112\n",
       "carle            5.769364             4.23667   10.006\n",
       "carte            5.795107             4.20188  9.99699\n",
       "soare            5.885203              4.1063  9.99151\n",
       "raile            5.865154             4.12528  9.99044\n",
       "roate            5.884856             4.09964   9.9845\n",
       "stare            5.806889             4.17742  9.98431\n",
       "caret            5.778207             4.19784  9.97604\n",
       "raine            5.786193             4.18608  9.97227\n",
       "irate            5.832799             4.13097  9.96377\n",
       "raise            5.878303             4.07497  9.95327\n",
       "orate            5.818944             4.13192  9.95086\n",
       "ariel            5.774557             4.16077  9.93532\n",
       "arise            5.821023             4.11102  9.93204\n",
       "taler            5.773100             4.15885  9.93195"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_step_entropy_df_20.sort_values(by = 'sum', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "directed-liberal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 2309 of 2309 | word: zonal |\n",
      "-------------------------\n",
      "â¬›ðŸŸ¨ðŸŸ¨ðŸŸ¨â¬›  slane  14\n",
      "ðŸŸ¨â¬›ðŸŸ©ðŸŸ©â¬›  lanai  2\n",
      "â¬›ðŸŸ©ðŸŸ©ðŸŸ©ðŸŸ©  tonal  1\n",
      "ðŸŸ©ðŸŸ©ðŸŸ©ðŸŸ©ðŸŸ©  zonal  \n",
      "\n",
      "\n",
      "-------------------------\n",
      "| total guess:  7936 | average guess: 3.4370 | guess number distribution: [   0.   65. 1231.  954.   57.    2.    0.] |\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-f61875b1fc2743e18de29edd0fdf3edf\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-f61875b1fc2743e18de29edd0fdf3edf\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-f61875b1fc2743e18de29edd0fdf3edf\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}, \"axisX\": {\"labelAngle\": 0}}, \"data\": {\"name\": \"data-a8c4844f31f5fabca5a3a736e28fa25b\"}, \"mark\": \"bar\", \"encoding\": {\"tooltip\": [{\"type\": \"nominal\", \"field\": \"number of guesses\"}, {\"type\": \"quantitative\", \"field\": \"count\"}], \"x\": {\"type\": \"ordinal\", \"field\": \"number of guesses\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"count\"}}, \"height\": 200, \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-a8c4844f31f5fabca5a3a736e28fa25b\": [{\"number of guesses\": \"1\", \"count\": 0.0}, {\"number of guesses\": \"2\", \"count\": 65.0}, {\"number of guesses\": \"3\", \"count\": 1231.0}, {\"number of guesses\": \"4\", \"count\": 954.0}, {\"number of guesses\": \"5\", \"count\": 57.0}, {\"number of guesses\": \"6\", \"count\": 2.0}, {\"number of guesses\": \"> 6\", \"count\": 0.0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-pakistan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-ethnic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-mother",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
