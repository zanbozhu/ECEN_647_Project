{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "corporate-bathroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import pickle\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import entropy\n",
    "import altair as alt\n",
    "from wordfreq import word_frequency\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "advanced-jason",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_guess_result(answer_word, guess_word):\n",
    "\n",
    "    guess_result = [0, 0, 0, 0, 0]\n",
    "    for i in range(5):\n",
    "        if guess_word[i] == answer_word[i]:\n",
    "            guess_result[i] = 2\n",
    "    \n",
    "    letter_count = {}\n",
    "    for i in range(5):\n",
    "        if guess_result[i] != 2:\n",
    "            if answer_word[i] not in letter_count:\n",
    "                letter_count[answer_word[i]] = 1\n",
    "            else:\n",
    "                letter_count[answer_word[i]] += 1\n",
    "    \n",
    "    for i in range(5):\n",
    "        if guess_result[i] != 2 and guess_word[i] in letter_count:\n",
    "            if letter_count[guess_word[i]] > 0:\n",
    "                guess_result[i] = 1\n",
    "                letter_count[guess_word[i]] -= 1\n",
    "\n",
    "    return int(''.join(str(n) for n in guess_result), 3)\n",
    "\n",
    "######################################################################################################################################################\n",
    "\n",
    "def display_result(answer_word, former_guesses, former_guess_results, num_choices_left, total_guess_number, result_distribution):\n",
    "\n",
    "    former_guesses = former_guesses[-6:]\n",
    "    former_guess_results = former_guess_results[-6:]\n",
    "    num_choices_left = num_choices_left[-6:]\n",
    "\n",
    "    ternary_string_guess_results = []\n",
    "    for number in former_guess_results:\n",
    "        ternary_string_guess_results.append(np.base_repr(number, base = 3).zfill(5))\n",
    "\n",
    "    if former_guess_results[-1] != 242:\n",
    "        if total_guess_number == 0:\n",
    "            average_guess = 0\n",
    "        else:\n",
    "            average_guess = total_guess_number / possible_words_list.index(answer_word)\n",
    "    else:\n",
    "        average_guess = total_guess_number / (possible_words_list.index(answer_word) + 1)\n",
    "\n",
    "    message_1 = ''.join(['| ', '{:4.0f}'.format(possible_words_list.index(answer_word) + 1), ' of ', str(len(possible_words_list)), ' | word: ', answer_word, ' |'])\n",
    "    message_2 = ''.join(['| total guess: ', '{:5.0f}'.format(total_guess_number), ' | average guess: ', '{:5.4f}'.format(average_guess), ' | guess number distribution: ', str(result_distribution), ' |'])\n",
    "\n",
    "    print(message_1)\n",
    "    print('-------------------------')\n",
    "\n",
    "    for result_display_line in range(6):\n",
    "        if result_display_line < len(ternary_string_guess_results):\n",
    "            result_string = ternary_string_guess_results[result_display_line]\n",
    "            new_result_string = ''\n",
    "            for string_bit in range(5):\n",
    "                if result_string[string_bit] == '0':\n",
    "                    new_result_string += '\\U00002B1B'\n",
    "                elif result_string[string_bit] == '1':\n",
    "                    new_result_string += '\\U0001F7E8'\n",
    "                elif result_string[string_bit] == '2':\n",
    "                    new_result_string += '\\U0001F7E9'\n",
    "            new_result_string += '  '\n",
    "            new_result_string += former_guesses[result_display_line]\n",
    "            new_result_string += '  '\n",
    "            new_result_string += str(num_choices_left[result_display_line])\n",
    "            print(new_result_string)\n",
    "        else:\n",
    "            print()\n",
    "\n",
    "    print('-------------------------')\n",
    "    print(message_2)\n",
    "\n",
    "######################################################################################################################################################\n",
    "\n",
    "def get_next_guess(former_guesses, former_guess_results):\n",
    "\n",
    "    possible_choices = np.arange(len(possible_words_list))\n",
    "    for i in range(len(former_guesses)):\n",
    "        possible_choices = np.intersect1d(possible_choices, np.where(guess_result_matrix[allowed_words_list.index(former_guesses[i])] == former_guess_results[i]))\n",
    "    \n",
    "    if len(former_guesses) == 1:\n",
    "        return best_second_guess_dict[former_guess_results[0]], len(possible_choices)\n",
    "    \n",
    "    else:\n",
    "        if len(possible_choices) == 1:\n",
    "            return possible_words_list[possible_choices[0]], len(possible_choices)\n",
    "        else:\n",
    "            sub_matrix = guess_result_matrix[np.ix_(np.arange(len(guess_result_matrix)), possible_choices)]\n",
    "            entropy_value_array = []\n",
    "            for i in range(len(sub_matrix)):\n",
    "                unique, counts = np.unique(sub_matrix[i], return_counts = True)\n",
    "                entropy_value_array.append(entropy(counts, base = 2))\n",
    "\n",
    "            argmax = np.where(entropy_value_array == np.max(entropy_value_array))\n",
    "            if np.in1d(np.array(possible_words_indices)[possible_choices], argmax).any():\n",
    "                best_next_guess = allowed_words_list[np.array(possible_words_indices)[possible_choices][np.in1d(np.array(possible_words_indices)[possible_choices], argmax)][0]]\n",
    "            else:\n",
    "                best_next_guess = allowed_words_list[np.argmax(entropy_value_array)]\n",
    "                \n",
    "            return best_next_guess, len(possible_choices)\n",
    "\n",
    "######################################################################################################################################################\n",
    "\n",
    "def demo():\n",
    "    \n",
    "    np.set_printoptions(suppress = True)\n",
    "    \n",
    "    result_distribution = np.zeros(7)\n",
    "    total_guess_number = 0\n",
    "\n",
    "    for answer_word in possible_words_list:\n",
    "\n",
    "        first_guess = 'slane'\n",
    "        guess_number = 0\n",
    "        former_guesses = []\n",
    "        former_guess_results = []\n",
    "        num_choices_left = []\n",
    "\n",
    "        guess_word = first_guess\n",
    "        while answer_word != guess_word:\n",
    "            guess_number += 1\n",
    "            guess_result = get_guess_result(answer_word, guess_word)\n",
    "            former_guesses.append(guess_word)\n",
    "            former_guess_results.append(guess_result)\n",
    "            next_guess, len_possible_choices = get_next_guess(former_guesses, former_guess_results)\n",
    "            num_choices_left.append(len_possible_choices)\n",
    "            guess_word = next_guess\n",
    "\n",
    "            clear_output(wait = True)\n",
    "            display_result(answer_word, former_guesses, former_guess_results, num_choices_left, total_guess_number, result_distribution)\n",
    "\n",
    "        former_guesses.append(answer_word)\n",
    "        former_guess_results.append(242)\n",
    "        num_choices_left.append('')\n",
    "        guess_number += 1\n",
    "        total_guess_number += guess_number\n",
    "        if guess_number <= 6:\n",
    "            result_distribution[guess_number - 1] += 1\n",
    "        else:\n",
    "            result_distribution[6] += 1\n",
    "\n",
    "        clear_output(wait = True)\n",
    "        display_result(answer_word, former_guesses, former_guess_results, num_choices_left, total_guess_number, result_distribution)\n",
    "\n",
    "    display(alt.Chart(pd.DataFrame({'number of guesses': [str(num) for num in np.arange(len(result_distribution) - 1) + 1] + ['> 6'], 'count': result_distribution})).mark_bar().encode(alt.X('number of guesses:O'), alt.Y('count:Q'), tooltip = ['number of guesses', 'count']).properties(width = 500, height = 200).configure_axisX(labelAngle = 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "infrared-disaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('possible_answers.txt') as file:\n",
    "    possible_words = file.readlines()\n",
    "possible_words_list = [word[:5] for word in possible_words]\n",
    "\n",
    "with open('allowed_guesses.txt') as file:\n",
    "    allowed_words = file.readlines()\n",
    "allowed_words_list = [word[:5] for word in allowed_words] + possible_words_list\n",
    "\n",
    "######################################################################################################################################################\n",
    "\n",
    "if 'guess_result_matrix.npy' not in os.listdir():\n",
    "    guess_result_matrix = []\n",
    "    for word1 in allowed_words_list:\n",
    "        word_guess_result_array = []\n",
    "        for word2 in allowed_words_list:\n",
    "            word_guess_result_array.append(get_guess_result(word2, word1))\n",
    "        guess_result_matrix.append(word_guess_result_array)\n",
    "    np.save('guess_result_matrix.npy', guess_result_matrix)\n",
    "else:\n",
    "    guess_result_matrix = np.load('guess_result_matrix.npy')\n",
    "\n",
    "possible_words_indices = []\n",
    "for i in range(len(possible_words_list)):\n",
    "    possible_words_indices.append(allowed_words_list.index(possible_words_list[i]))\n",
    "guess_result_matrix = guess_result_matrix[np.ix_(np.arange(len(guess_result_matrix)), possible_words_indices)]\n",
    "\n",
    "######################################################################################################################################################\n",
    "\n",
    "if 'best_second_guess_dict_v3_2_slane.pkl' not in os.listdir():\n",
    "\n",
    "    unique, counts = np.unique(guess_result_matrix[allowed_words_list.index('slane')], return_counts = True)\n",
    "\n",
    "    best_second_guess_array = []\n",
    "    for possible_result in unique:\n",
    "\n",
    "        possible_choices = np.where(guess_result_matrix[allowed_words_list.index('slane')] == possible_result)[0]\n",
    "\n",
    "        if len(possible_choices) == 1:\n",
    "            best_second_guess = possible_words_list[possible_choices[0]]\n",
    "        else:\n",
    "            sub_matrix = guess_result_matrix[np.ix_(np.arange(len(guess_result_matrix)), possible_choices)]\n",
    "            entropy_value_array = []\n",
    "            for i in range(len(sub_matrix)):\n",
    "                unique_2, counts_2 = np.unique(sub_matrix[i], return_counts = True)\n",
    "                entropy_value_array.append(entropy(counts_2, base = 2))\n",
    "\n",
    "            argmax = np.where(entropy_value_array == np.max(entropy_value_array))\n",
    "            if np.in1d(np.array(possible_words_indices)[possible_choices], argmax).any():\n",
    "                best_second_guess = allowed_words_list[np.array(possible_words_indices)[possible_choices][np.in1d(np.array(possible_words_indices)[possible_choices], argmax)][0]]\n",
    "            else:\n",
    "                best_second_guess = allowed_words_list[np.argmax(entropy_value_array)]\n",
    "\n",
    "        best_second_guess_array.append(best_second_guess)\n",
    "\n",
    "    best_second_guess_dict = dict(zip(unique, best_second_guess_array))\n",
    "    pickle.dump(best_second_guess_dict, open('best_second_guess_dict_v3_2_slane.pkl', 'wb'))\n",
    "\n",
    "else:\n",
    "    best_second_guess_dict = pickle.load(open('best_second_guess_dict_v3_2_slane.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "regulated-fundamentals",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_guess_entropy_array = []\n",
    "for i in range(len(guess_result_matrix)):\n",
    "    unique, counts = np.unique(guess_result_matrix[i], return_counts = True)\n",
    "    first_guess_entropy_array.append(entropy(counts, base = 2))\n",
    "\n",
    "if 'two_step_entropy_df_20_v3_2.pkl' not in os.listdir():\n",
    "\n",
    "    two_step_entropy_df = pd.DataFrame(index = allowed_words_list, columns = ['first_step_entropy', 'second_step_entropy', 'sum'])\n",
    "    two_step_entropy_df['first_step_entropy'] = first_guess_entropy_array\n",
    "    two_step_entropy_df_20 = two_step_entropy_df.sort_values(by = 'first_step_entropy', ascending = False)[:20]\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "    for first_word in two_step_entropy_df_20.index:\n",
    "\n",
    "        unique, counts = np.unique(guess_result_matrix[allowed_words_list.index(first_word)], return_counts = True)\n",
    "\n",
    "        expected_second_step_entropy = 0\n",
    "        for i in range(len(unique)):\n",
    "            guess_result = unique[i]\n",
    "            guess_result_weight = counts[i] / np.sum(counts)\n",
    "\n",
    "            if counts[i] == 1:\n",
    "                max_second_entropy = 0\n",
    "            elif counts[i] == 2:\n",
    "                max_second_entropy = 1\n",
    "            else:\n",
    "                possible_choices = np.where(guess_result_matrix[allowed_words_list.index(first_word)] == guess_result)[0]\n",
    "                sub_matrix = guess_result_matrix[np.ix_(np.arange(len(guess_result_matrix)), possible_choices)]\n",
    "\n",
    "                second_entropy_value_array = []\n",
    "                for j in range(len(sub_matrix)):\n",
    "                    unique_2, counts_2 = np.unique(sub_matrix[j], return_counts = True)\n",
    "                    second_entropy_value_array.append(entropy(counts_2, base = 2))\n",
    "                max_second_entropy = np.max(second_entropy_value_array)\n",
    "\n",
    "            expected_second_step_entropy += guess_result_weight * max_second_entropy\n",
    "\n",
    "\n",
    "        two_step_entropy_df_20.at[first_word, 'second_step_entropy'] = expected_second_step_entropy\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "    two_step_entropy_df_20['sum'] = two_step_entropy_df_20['first_step_entropy'] + two_step_entropy_df_20['second_step_entropy']\n",
    "    pickle.dump(two_step_entropy_df_20, open('two_step_entropy_df_20_v3_2.pkl', 'wb'))\n",
    "\n",
    "else:\n",
    "    two_step_entropy_df_20 = pickle.load(open('two_step_entropy_df_20_v3_2.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cheap-documentation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_step_entropy</th>\n",
       "      <th>second_step_entropy</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>slane</th>\n",
       "      <td>5.770181</td>\n",
       "      <td>4.26583</td>\n",
       "      <td>10.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slate</th>\n",
       "      <td>5.855775</td>\n",
       "      <td>4.17783</td>\n",
       "      <td>10.0336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salet</th>\n",
       "      <td>5.834582</td>\n",
       "      <td>4.18197</td>\n",
       "      <td>10.0166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace</th>\n",
       "      <td>5.830549</td>\n",
       "      <td>4.18355</td>\n",
       "      <td>10.0141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crate</th>\n",
       "      <td>5.834874</td>\n",
       "      <td>4.17802</td>\n",
       "      <td>10.0129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reast</th>\n",
       "      <td>5.865457</td>\n",
       "      <td>4.14487</td>\n",
       "      <td>10.0103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carle</th>\n",
       "      <td>5.770479</td>\n",
       "      <td>4.23622</td>\n",
       "      <td>10.0067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carte</th>\n",
       "      <td>5.794557</td>\n",
       "      <td>4.20287</td>\n",
       "      <td>9.99742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soare</th>\n",
       "      <td>5.885960</td>\n",
       "      <td>4.10815</td>\n",
       "      <td>9.99411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raile</th>\n",
       "      <td>5.865710</td>\n",
       "      <td>4.12739</td>\n",
       "      <td>9.9931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roate</th>\n",
       "      <td>5.882779</td>\n",
       "      <td>4.10438</td>\n",
       "      <td>9.98716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stare</th>\n",
       "      <td>5.807280</td>\n",
       "      <td>4.17744</td>\n",
       "      <td>9.98472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caret</th>\n",
       "      <td>5.776713</td>\n",
       "      <td>4.20031</td>\n",
       "      <td>9.97702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raine</th>\n",
       "      <td>5.786710</td>\n",
       "      <td>4.18753</td>\n",
       "      <td>9.97424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irate</th>\n",
       "      <td>5.831397</td>\n",
       "      <td>4.13314</td>\n",
       "      <td>9.96454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raise</th>\n",
       "      <td>5.877910</td>\n",
       "      <td>4.07914</td>\n",
       "      <td>9.95705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orate</th>\n",
       "      <td>5.817161</td>\n",
       "      <td>4.13606</td>\n",
       "      <td>9.95322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ariel</th>\n",
       "      <td>5.775167</td>\n",
       "      <td>4.16242</td>\n",
       "      <td>9.93759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arise</th>\n",
       "      <td>5.820940</td>\n",
       "      <td>4.11283</td>\n",
       "      <td>9.93377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taler</th>\n",
       "      <td>5.770612</td>\n",
       "      <td>4.16066</td>\n",
       "      <td>9.93127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       first_step_entropy second_step_entropy      sum\n",
       "slane            5.770181             4.26583   10.036\n",
       "slate            5.855775             4.17783  10.0336\n",
       "salet            5.834582             4.18197  10.0166\n",
       "trace            5.830549             4.18355  10.0141\n",
       "crate            5.834874             4.17802  10.0129\n",
       "reast            5.865457             4.14487  10.0103\n",
       "carle            5.770479             4.23622  10.0067\n",
       "carte            5.794557             4.20287  9.99742\n",
       "soare            5.885960             4.10815  9.99411\n",
       "raile            5.865710             4.12739   9.9931\n",
       "roate            5.882779             4.10438  9.98716\n",
       "stare            5.807280             4.17744  9.98472\n",
       "caret            5.776713             4.20031  9.97702\n",
       "raine            5.786710             4.18753  9.97424\n",
       "irate            5.831397             4.13314  9.96454\n",
       "raise            5.877910             4.07914  9.95705\n",
       "orate            5.817161             4.13606  9.95322\n",
       "ariel            5.775167             4.16242  9.93759\n",
       "arise            5.820940             4.11283  9.93377\n",
       "taler            5.770612             4.16066  9.93127"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_step_entropy_df_20.sort_values(by = 'sum', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "institutional-designation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 2315 of 2315 | word: zonal |\n",
      "-------------------------\n",
      "â¬›ðŸŸ¨ðŸŸ¨ðŸŸ¨â¬›  slane  14\n",
      "ðŸŸ¨â¬›ðŸŸ©ðŸŸ©â¬›  lanai  2\n",
      "â¬›ðŸŸ©ðŸŸ©ðŸŸ©ðŸŸ©  tonal  1\n",
      "ðŸŸ©ðŸŸ©ðŸŸ©ðŸŸ©ðŸŸ©  zonal  \n",
      "\n",
      "\n",
      "-------------------------\n",
      "| total guess:  7962 | average guess: 3.4393 | guess number distribution: [   0.   65. 1227.  966.   55.    2.    0.] |\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-24e588ccd81e47e49beeca1056080bf4\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-24e588ccd81e47e49beeca1056080bf4\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-24e588ccd81e47e49beeca1056080bf4\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}, \"axisX\": {\"labelAngle\": 0}}, \"data\": {\"name\": \"data-551e717e4bbff288fba4c9ad313bbef2\"}, \"mark\": \"bar\", \"encoding\": {\"tooltip\": [{\"type\": \"nominal\", \"field\": \"number of guesses\"}, {\"type\": \"quantitative\", \"field\": \"count\"}], \"x\": {\"type\": \"ordinal\", \"field\": \"number of guesses\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"count\"}}, \"height\": 200, \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-551e717e4bbff288fba4c9ad313bbef2\": [{\"number of guesses\": \"1\", \"count\": 0.0}, {\"number of guesses\": \"2\", \"count\": 65.0}, {\"number of guesses\": \"3\", \"count\": 1227.0}, {\"number of guesses\": \"4\", \"count\": 966.0}, {\"number of guesses\": \"5\", \"count\": 55.0}, {\"number of guesses\": \"6\", \"count\": 2.0}, {\"number of guesses\": \"> 6\", \"count\": 0.0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-heating",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-helen",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-listing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
